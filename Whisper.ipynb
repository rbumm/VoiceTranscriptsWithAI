{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chrome-headless-browser\n",
    "!pip install --upgrade youtube_dl\n",
    "!pip install ffmpeg\n",
    "!pip install ffprobe\n",
    "!pip install -U selenium_profiles pyChatGPT\n",
    "# install chromedriver\n",
    "!pip install whisper\n",
    "!pip install pydub\n",
    "!pip install gradio\n",
    "!pip install soundfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "!pip install pyttsx3\n",
    "import pyttsx3\n",
    "\n",
    "\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "\n",
    "def save_and_transcribe(audio):\n",
    "\n",
    "    #   Global variable to hold the chat history, initialise with system role\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an intelligent professor.\"}\n",
    "        ]\n",
    "    \n",
    "    audio_file = open(audio, 'rb')\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    audio_file.close()\n",
    "       \n",
    "    #   ChatGPT API\n",
    "\n",
    "#   append user's input to conversation\n",
    "    conversation.append({\"role\": \"user\", \"content\": transcript[\"text\"]})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=conversation\n",
    "    )\n",
    "    \n",
    "    print(response)\n",
    "    system_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    totalresponse = \"\"\n",
    "    totalresponse  = \"<p><strong>Transcript:</strong><br>\" + transcript[\"text\"] + \"</p>\"\n",
    "     totalresponse += \"<p><strong>CHATGPT:</strong><br>\" + system_message + \"</p>\"\n",
    "\n",
    "    return totalresponse\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=save_and_transcribe,\n",
    "    inputs=gr.inputs.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    outputs='html',\n",
    "    title='Transcribe Audio',\n",
    "    description='Record audio using your microphone and transcribe it using OpenAI Whisper ASR system.',\n",
    ")\n",
    "\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbumm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
